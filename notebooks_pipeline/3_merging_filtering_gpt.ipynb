{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5429eb14-f760-4362-a3c5-47d617343932",
   "metadata": {},
   "source": [
    "# We can now merge and filter our image dataset to those images labeled as having high-quality, close-up flower photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eb1cae0-5e94-4bc6-b9c5-57d7d1eb10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84749c8b-4c8e-4903-8717-b918648c5e7c",
   "metadata": {},
   "source": [
    "# First: Merge the GPT responses into one big dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdacb39-dc0b-4085-87d2-24c5b72c82ef",
   "metadata": {},
   "source": [
    "### Access csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5416c0-e89c-441d-a7ac-8b9360625fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use glob to do a pattern matching query\n",
    "csv_files = glob.glob(\"./gpt_raw_labeling/*_to_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c98ec59-484a-40be-8a52-67ec8acc623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./gpt_raw_labeling/31000_to_32000.csv',\n",
       " './gpt_raw_labeling/37000_to_38000.csv',\n",
       " './gpt_raw_labeling/12000_to_14000.csv',\n",
       " './gpt_raw_labeling/34000_to_35000.csv',\n",
       " './gpt_raw_labeling/32000_to_33000.csv',\n",
       " './gpt_raw_labeling/6000_to_8000.csv',\n",
       " './gpt_raw_labeling/0_to_2000.csv',\n",
       " './gpt_raw_labeling/29000_to_30000.csv',\n",
       " './gpt_raw_labeling/41000_to_41069.csv',\n",
       " './gpt_raw_labeling/24000_to_25000.csv',\n",
       " './gpt_raw_labeling/22000_to_23000.csv',\n",
       " './gpt_raw_labeling/4000_to_6000.csv',\n",
       " './gpt_raw_labeling/27000_to_28000.csv',\n",
       " './gpt_raw_labeling/21000_to_22000.csv',\n",
       " './gpt_raw_labeling/14000_to_16000.csv',\n",
       " './gpt_raw_labeling/2000_to_4000.csv',\n",
       " './gpt_raw_labeling/33000_to_34000.csv',\n",
       " './gpt_raw_labeling/16000_to_18000.csv',\n",
       " './gpt_raw_labeling/10000_to_12000.csv',\n",
       " './gpt_raw_labeling/25000_to_26000.csv',\n",
       " './gpt_raw_labeling/38000_to_39000.csv',\n",
       " './gpt_raw_labeling/8000_to_10000.csv',\n",
       " './gpt_raw_labeling/39000_to_40000.csv',\n",
       " './gpt_raw_labeling/20000_to_21000.csv',\n",
       " './gpt_raw_labeling/26000_to_27000.csv',\n",
       " './gpt_raw_labeling/40000_to_41000.csv',\n",
       " './gpt_raw_labeling/18000_to_20000.csv',\n",
       " './gpt_raw_labeling/30000_to_31000.csv',\n",
       " './gpt_raw_labeling/36000_to_37000.csv',\n",
       " './gpt_raw_labeling/28000_to_29000.csv',\n",
       " './gpt_raw_labeling/35000_to_36000.csv',\n",
       " './gpt_raw_labeling/23000_to_24000.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a670ea-372e-473c-8058-7d60c8a83d76",
   "metadata": {},
   "source": [
    "### Sort the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb2d18dc-7ab7-443b-96d0-9eec46edb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort files by the starting index extracted from the filename.\n",
    "def get_starting_index(filename):\n",
    "    basename = os.path.basename(filename)\n",
    "    # re to pull out index\n",
    "    m = re.match(r\"(\\d+)_to_\\d+\\.csv\", basename)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    else:\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec50fc0-0592-4095-9af9-47ff00c1cbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./gpt_raw_labeling/0_to_2000.csv',\n",
       " './gpt_raw_labeling/2000_to_4000.csv',\n",
       " './gpt_raw_labeling/4000_to_6000.csv',\n",
       " './gpt_raw_labeling/6000_to_8000.csv',\n",
       " './gpt_raw_labeling/8000_to_10000.csv',\n",
       " './gpt_raw_labeling/10000_to_12000.csv',\n",
       " './gpt_raw_labeling/12000_to_14000.csv',\n",
       " './gpt_raw_labeling/14000_to_16000.csv',\n",
       " './gpt_raw_labeling/16000_to_18000.csv',\n",
       " './gpt_raw_labeling/18000_to_20000.csv',\n",
       " './gpt_raw_labeling/20000_to_21000.csv',\n",
       " './gpt_raw_labeling/21000_to_22000.csv',\n",
       " './gpt_raw_labeling/22000_to_23000.csv',\n",
       " './gpt_raw_labeling/23000_to_24000.csv',\n",
       " './gpt_raw_labeling/24000_to_25000.csv',\n",
       " './gpt_raw_labeling/25000_to_26000.csv',\n",
       " './gpt_raw_labeling/26000_to_27000.csv',\n",
       " './gpt_raw_labeling/27000_to_28000.csv',\n",
       " './gpt_raw_labeling/28000_to_29000.csv',\n",
       " './gpt_raw_labeling/29000_to_30000.csv',\n",
       " './gpt_raw_labeling/30000_to_31000.csv',\n",
       " './gpt_raw_labeling/31000_to_32000.csv',\n",
       " './gpt_raw_labeling/32000_to_33000.csv',\n",
       " './gpt_raw_labeling/33000_to_34000.csv',\n",
       " './gpt_raw_labeling/34000_to_35000.csv',\n",
       " './gpt_raw_labeling/35000_to_36000.csv',\n",
       " './gpt_raw_labeling/36000_to_37000.csv',\n",
       " './gpt_raw_labeling/37000_to_38000.csv',\n",
       " './gpt_raw_labeling/38000_to_39000.csv',\n",
       " './gpt_raw_labeling/39000_to_40000.csv',\n",
       " './gpt_raw_labeling/40000_to_41000.csv',\n",
       " './gpt_raw_labeling/41000_to_41069.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = sorted(csv_files, key=get_starting_index)\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57add094-5434-49b0-8e98-4acf107dded9",
   "metadata": {},
   "source": [
    "### Build the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363fc151-6dc7-4093-8683-631758a928f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of dfs\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "# concat all dfs into one big one\n",
    "# ignore_index resets the idxs\n",
    "df_all = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac12af80-dce4-4a05-9a1f-776490a46ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   global_index flower_present\n",
      "0             0            YES\n",
      "1             1             NO\n",
      "2             2            YES\n",
      "3             3             NO\n",
      "4             4            YES\n",
      "Final DataFrame shape: (41069, 2)\n"
     ]
    }
   ],
   "source": [
    "# make a new column 'global_index' that spans from 0 to the total number of rows minus one - \n",
    "# should match index, but want to make sure we don't lose it!\n",
    "df_all['global_index'] = range(len(df_all))\n",
    "\n",
    "# nice to reorder the columns so the global index as the first column\n",
    "cols = ['global_index'] + [col for col in df_all.columns if col != 'global_index']\n",
    "df_all = df_all[cols]\n",
    "\n",
    "# df_all contains all concat data with a global index\n",
    "print(df_all.head())\n",
    "print(\"Final DataFrame shape:\", df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c32d5e4-ceb9-4425-a60e-3f2c5ded8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('./gpt_image_filtering.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc7a7c-42d2-4d6a-9a94-f4e1f71a6a95",
   "metadata": {},
   "source": [
    "# Second: Filter the full image dataset using the GPT labels to create a separate dataset of high-quality flower images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c968beb8-3b4b-4050-b893-9d83d287da5a",
   "metadata": {},
   "source": [
    "### Get the image idxs that were labeled YES by GPT as having high-quality photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b54ac5-977b-4326-94e2-f1c9f0915125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df to only include rows with \"YES\" for flower_present\n",
    "yes_df = df_all[df_all['flower_present'] == \"YES\"]\n",
    "\n",
    "# get the list of indices (which map the image file names)\n",
    "yes_indices = yes_df['global_index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "704eadc5-87c0-4f09-9a15-50eb605df10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20761"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many YES values\n",
    "len(yes_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb60bc-a7a9-4174-b814-02398b8d09a1",
   "metadata": {},
   "source": [
    "### Copy over the corresponding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f007828-34ce-4918-8785-7caf8070b8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered images copied successfully!\n"
     ]
    }
   ],
   "source": [
    "# define the source directory where the original dataset of all images is stored\n",
    "source_dir = '/Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/'  # e.g., '/Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/'\n",
    "\n",
    "# define the dest directory where filtered images will end up\n",
    "target_dir = '/Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/gpt_filtered_images/'\n",
    "os.makedirs(target_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# loop through and copy each image\n",
    "for idx in yes_indices:\n",
    "    source_path = os.path.join(source_dir, f\"{idx}.jpg\")\n",
    "    target_path = os.path.join(target_dir, f\"{idx}.jpg\")\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.copy(source_path, target_path)\n",
    "    else:\n",
    "        print(f\"Warning: {source_path} does not exist.\")\n",
    "\n",
    "print(\"Filtered images copied successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4377737-ccec-4e16-a968-7434826e5be6",
   "metadata": {},
   "source": [
    "### Make a directory with segmentation model training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc7486b0-997b-4ccf-a89b-cb68cb900cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target directory where the filtered images will be copied\n",
    "source_dir = '/Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/gpt_filtered_images/'\n",
    "target_dir = '/Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/semantic_segmentation_training/'\n",
    "os.makedirs(target_dir, exist_ok=True)  # make dir if doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c3d3653-b2ce-4f86-be8d-4273eab8a317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33419, 37864, 11334, 30136, 32800,  8869,   264,  6692, 17831,\n",
       "       31976,   919, 25643, 11103,  6386,  5732, 27825,   360, 16756,\n",
       "       25880, 26668,  3246, 14191,  5709, 23297, 32974, 14768,  7193,\n",
       "       13781,  6476,  3796,  1164,  9148, 25945, 26226, 36251, 14224,\n",
       "       20917, 26141, 29006,  7636, 36655,    84, 27507, 22132, 32914,\n",
       "       21043, 37685, 23497,  1416,  8551,   428,  5316,  9242, 15088,\n",
       "        7212, 37749, 14739, 21768, 33532,  1734,  6921, 17613,  7544,\n",
       "       38418, 12245, 21661, 12435, 26680, 37485, 16985, 27359,   233,\n",
       "       19400, 11858, 25440, 10976, 13237,  7491, 40479, 19806, 26306,\n",
       "        7141, 25386, 17124,  5059, 22187,  3990,  5237, 31554, 28732,\n",
       "       19193, 31985, 38433, 31039, 12624,  7435, 15422, 13371, 13709,\n",
       "       34151, 33690, 33246, 11437, 14949, 39978,  1571, 33131, 33354,\n",
       "       14078,  8268, 23554, 27546, 24899, 20507,  9872, 14400,  3208,\n",
       "       31496,  5715, 29902, 30360, 23281,  5917, 21682, 38429, 19449,\n",
       "       19777, 15567, 33790, 24829, 28168, 25658,  8890, 21020, 41032,\n",
       "       39060, 21797,  7068, 21409,  4197, 28558, 19240,   944, 32428,\n",
       "       15611, 28815, 13560, 37577, 20583,  3794, 16167, 37739, 16482,\n",
       "       31828,  9161, 39841, 37333, 19605, 12731, 25375, 36524, 26397,\n",
       "       12015, 34466, 16440, 28072, 10552, 11932, 16123, 22308, 12892,\n",
       "       25640, 27857,  9158, 30203, 30576,  6182, 26307, 36274, 10276,\n",
       "       21476, 29064, 21114, 34813,  4565, 19840, 28441, 23961, 28010,\n",
       "       34472,  2826, 18082, 15262,  2988,    87, 35867,  7981, 27630,\n",
       "       20698,  7038])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_idxs = np.random.choice(yes_indices,200)\n",
    "selected_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313ad396-b0f8-471e-be76-dea0be4697b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered images copied successfully!\n"
     ]
    }
   ],
   "source": [
    "# loop through the indices and copy each image\n",
    "for idx in selected_idxs:\n",
    "    source_path = os.path.join(source_dir, f\"{idx}.jpg\")\n",
    "    target_path = os.path.join(target_dir, f\"{idx}.jpg\")\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.copy(source_path, target_path)\n",
    "    else:\n",
    "        print(f\"Warning: {source_path} does not exist.\")\n",
    "\n",
    "print(\"Filtered images copied successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
