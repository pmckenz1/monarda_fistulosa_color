{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c6bfab-a640-4c2b-922b-c8260a710212",
   "metadata": {},
   "source": [
    "# Pipeline for submitting images to GPT to query whether they contain a high-quality view of Monarda flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8fe39d-8766-48a4-9f49-50670257cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import time\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# load gpt client\n",
    "client = OpenAI(\n",
    "    api_key='your-key-here' # fill in api key here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6897ebc-d95f-4daf-a452-8595ba6aec0f",
   "metadata": {},
   "source": [
    "### Image processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9b14d8-c3f8-4d4e-a0be-bc6b04d4017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process an image from a local file\n",
    "def process_image(idx, file_path):\n",
    "    retries = 3\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            # open image from disk\n",
    "            image = Image.open(file_path)\n",
    "            original_width, original_height = image.size\n",
    "\n",
    "            # set new dimensions but keep ratio\n",
    "            if original_width >= original_height:\n",
    "                new_width = 512\n",
    "                new_height = int((new_width / original_width) * original_height)\n",
    "            else:\n",
    "                new_height = 512\n",
    "                new_width = int((new_height / original_height) * original_width)\n",
    "\n",
    "            # resize\n",
    "            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "            # save resized image into a jpeg bytes buffer\n",
    "            buffered = BytesIO()\n",
    "            image.save(buffered, format=\"JPEG\")\n",
    "            resized_image_data = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "            # build query for gpt api\n",
    "            return {\n",
    "                \"custom_id\": f\"task-{idx}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\"type\": \"text\", \"text\": query},\n",
    "                                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{resized_image_data}\"}}\n",
    "                            ],\n",
    "                        }\n",
    "                    ],\n",
    "                    \"max_tokens\": 300\n",
    "                }\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {file_path} at index {idx}, attempt {attempt + 1}: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(1)  # wait a sec before retry\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1072375e-1882-49bf-a412-c5a7c5d3c549",
   "metadata": {},
   "source": [
    "### Set up query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d860c9a-2f45-4f25-b686-724714b1053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the query\n",
    "query = (\"Answer with one word, either: YES, if this photo is of close-up \\\n",
    "beebalm flowers (usually lavender in color), or NO, if the photo is not close up, not of a flower, \\\n",
    "or low quality somehow. If it is just a bare seed head or leaves, your answer should be NO.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b3d0e-3951-41ca-988e-50a150380e66",
   "metadata": {},
   "source": [
    "Maximum json file size is 200MB, and maximum query number for one batch submission is 50,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9ac46-6f32-43f0-a45f-5e2a8e1e8411",
   "metadata": {},
   "source": [
    "# Loop method to perform async in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55410a68-a0aa-4d4a-aa46-8298f3fc4d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/20130.jpg at index 130, attempt 1: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/20130.jpg at index 130, attempt 2: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/20130.jpg at index 130, attempt 3: cannot write mode RGBA as JPEG\n",
      "Batch job submitted for images 20000:21000 with job ID batch_67b7363248b08190b38721ade7062af7\n",
      "Batch job submitted for images 21000:22000 with job ID batch_67b73693caec8190b2aa49cc717197cc\n",
      "Batch job submitted for images 22000:23000 with job ID batch_67b736f4a1388190ade998575955d512\n",
      "Batch job submitted for images 23000:24000 with job ID batch_67b73752753881909cd8da24ade97e0f\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/24783.jpg at index 783, attempt 1: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/24783.jpg at index 783, attempt 2: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/24783.jpg at index 783, attempt 3: cannot write mode RGBA as JPEG\n",
      "Batch job submitted for images 24000:25000 with job ID batch_67b737b1a0888190ab5994c489be36b5\n",
      "Batch job submitted for images 25000:26000 with job ID batch_67b7380f40788190a47a269e3983128b\n",
      "Batch job submitted for images 26000:27000 with job ID batch_67b73871df408190b6d607cd77621322\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/27231.jpg at index 231, attempt 1: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/27231.jpg at index 231, attempt 2: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/27231.jpg at index 231, attempt 3: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/27232.jpg at index 232, attempt 1: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/27232.jpg at index 232, attempt 2: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/27232.jpg at index 232, attempt 3: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/27233.jpg at index 233, attempt 1: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/27233.jpg at index 233, attempt 2: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/27233.jpg at index 233, attempt 3: cannot write mode RGBA as JPEG\n",
      "Batch job submitted for images 27000:28000 with job ID batch_67b738d7d60081908897af172d81d523\n",
      "Batch job submitted for images 28000:29000 with job ID batch_67b73937e9e08190aa7b52b6c0647ef3\n",
      "Batch job submitted for images 29000:30000 with job ID batch_67b7399603b88190a40d440a69943754\n",
      "Batch job submitted for images 30000:31000 with job ID batch_67b739f008a88190998053547948ef1f\n",
      "Batch job submitted for images 31000:32000 with job ID batch_67b73a4a4a6c8190b7e3a714cf9a1569\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/32740.jpg at index 740, attempt 1: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/32740.jpg at index 740, attempt 2: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/32740.jpg at index 740, attempt 3: cannot write mode RGBA as JPEG\n",
      "Batch job submitted for images 32000:33000 with job ID batch_67b73aabd6bc81908cb016812623bbf2\n",
      "Batch job submitted for images 33000:34000 with job ID batch_67b73b0b9cac8190848cdee8b6b1f648\n",
      "Batch job submitted for images 34000:35000 with job ID batch_67b73b6a2cf88190bdcc07ac0d28341c\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/35083.jpg at index 83, attempt 1: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/35083.jpg at index 83, attempt 2: cannot write mode RGBA as JPEG\n",
      "Error processing image /Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/35083.jpg at index 83, attempt 3: cannot write mode RGBA as JPEG\n",
      "Batch job submitted for images 35000:36000 with job ID batch_67b73bc88e688190a28f026754e5a802\n",
      "Batch job submitted for images 36000:37000 with job ID batch_67b73c27e2008190818a65b786ba2c9e\n",
      "Batch job submitted for images 37000:38000 with job ID batch_67b73c8a431c8190aa028340ad30e89e\n",
      "Batch job submitted for images 38000:39000 with job ID batch_67b73ce8b4f48190a7dce58a9ecad75f\n",
      "Batch job submitted for images 39000:40000 with job ID batch_67b73d597354819092990fedf568b77b\n",
      "Batch job submitted for images 40000:41000 with job ID batch_67b73dc7be0c81909f46ed62a48c2c37\n",
      "Job metadata saved to job_metadata.json.\n"
     ]
    }
   ],
   "source": [
    "# overall settings\n",
    "start_overall = 20000 # use these to specify which idxs to run\n",
    "stop_overall = 41000\n",
    "step = 1000\n",
    "\n",
    "# file name to store meta\n",
    "job_metadata_file = \"job_metadata.json\"\n",
    "\n",
    "# dict to store job meta, keys= job id\n",
    "jobs = {}\n",
    "\n",
    "# batch submit loop: submit all batches in async\n",
    "for starter_val in range(start_overall, stop_overall, step):\n",
    "    # make a list of file paths to images for curr batch\n",
    "    file_names = [f\"{i}.jpg\" for i in range(starter_val, starter_val + step)]\n",
    "    file_paths = [os.path.join('/Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/', fname)\n",
    "                  for fname in file_names]\n",
    "\n",
    "    # write out local batch submission file( unique file name per batch)\n",
    "    batch_task_filename = f\"batch_tasks_{starter_val}_{starter_val+step}.jsonl\"\n",
    "    with open(batch_task_filename, 'w') as file:\n",
    "        for idx in range(len(file_paths)):\n",
    "            task = process_image(idx, file_paths[idx])\n",
    "            if task:\n",
    "                file.write(json.dumps(task) + '\\n')\n",
    "    \n",
    "    # submit the batch file to api\n",
    "    batch_file = client.files.create(\n",
    "        file=open(batch_task_filename, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=batch_file.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "    print(f\"Batch job submitted for images {starter_val}:{starter_val+step} with job ID {batch_job.id}\")\n",
    "    \n",
    "    # save metadata for later polling/processing\n",
    "    jobs[batch_job.id] = {\n",
    "        \"starter_val\": starter_val,\n",
    "        \"step\": step,\n",
    "        \"batch_task_filename\": batch_task_filename\n",
    "    }\n",
    "    \n",
    "    # might as well space them out a bit\n",
    "    time.sleep(1)\n",
    "    \n",
    "# write job meta to a file for persistence,\n",
    "# ie can reload later\n",
    "with open(job_metadata_file, 'w') as f:\n",
    "    json.dump(jobs, f, indent=4)\n",
    "print(f\"Job metadata saved to {job_metadata_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40c35c4a-f2d2-4888-81fe-d72c1572a9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job metadata reloaded.\n"
     ]
    }
   ],
   "source": [
    "# reload job metadata for polling status\n",
    "with open(job_metadata_file, 'r') as f:\n",
    "    jobs = json.load(f)\n",
    "print(\"Job metadata reloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66e4a5cb-b364-4b19-a11c-018ea26ce902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job batch_67b7363248b08190b38721ade7062af7 (images 20000:21000) completed.\n",
      "Job batch_67b73693caec8190b2aa49cc717197cc (images 21000:22000) completed.\n",
      "Job batch_67b736f4a1388190ade998575955d512 (images 22000:23000) completed.\n",
      "Job batch_67b73752753881909cd8da24ade97e0f (images 23000:24000) completed.\n",
      "Job batch_67b737b1a0888190ab5994c489be36b5 (images 24000:25000) completed.\n",
      "Job batch_67b7380f40788190a47a269e3983128b (images 25000:26000) completed.\n",
      "Job batch_67b73871df408190b6d607cd77621322 (images 26000:27000) completed.\n",
      "Job batch_67b738d7d60081908897af172d81d523 (images 27000:28000) completed.\n",
      "Job batch_67b73937e9e08190aa7b52b6c0647ef3 (images 28000:29000) completed.\n",
      "Job batch_67b7399603b88190a40d440a69943754 (images 29000:30000) completed.\n",
      "Job batch_67b739f008a88190998053547948ef1f (images 30000:31000) completed.\n",
      "Job batch_67b73a4a4a6c8190b7e3a714cf9a1569 (images 31000:32000) completed.\n",
      "Job batch_67b73aabd6bc81908cb016812623bbf2 (images 32000:33000) completed.\n",
      "Job batch_67b73b0b9cac8190848cdee8b6b1f648 (images 33000:34000) completed.\n",
      "Job batch_67b73b6a2cf88190bdcc07ac0d28341c (images 34000:35000) completed.\n",
      "Job batch_67b73bc88e688190a28f026754e5a802 (images 35000:36000) completed.\n",
      "Job batch_67b73c27e2008190818a65b786ba2c9e (images 36000:37000) completed.\n",
      "Job batch_67b73c8a431c8190aa028340ad30e89e (images 37000:38000) completed.\n",
      "Job batch_67b73ce8b4f48190a7dce58a9ecad75f (images 38000:39000) completed.\n",
      "Job batch_67b73d597354819092990fedf568b77b (images 39000:40000) completed.\n",
      "Job batch_67b73dc7be0c81909f46ed62a48c2c37 (images 40000:41000) completed.\n",
      "All jobs are now complete. Processing results...\n"
     ]
    }
   ],
   "source": [
    "# polling... check all submitted jobs until all are complete (or failed)\n",
    "completed_jobs = {}\n",
    "while len(completed_jobs) < len(jobs):\n",
    "    for job_id in jobs:\n",
    "        if job_id in completed_jobs:\n",
    "            continue  # skip jobs that are done\n",
    "        job = client.batches.retrieve(job_id)\n",
    "        meta = jobs[job_id]\n",
    "        if job.failed_at:\n",
    "            print(f\"Job {job_id} (images {meta['starter_val']}:{meta['starter_val']+meta['step']}) failed!\")\n",
    "            completed_jobs[job_id] = job  # record as finished (failed)\n",
    "        elif job.completed_at:\n",
    "            print(f\"Job {job_id} (images {meta['starter_val']}:{meta['starter_val']+meta['step']}) completed.\")\n",
    "            completed_jobs[job_id] = job\n",
    "        # other= job is still running\n",
    "    # wait and then poll again\n",
    "    time.sleep(30)\n",
    "\n",
    "print(\"All jobs are now complete. Processing results...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b75b642e-e5c1-4c1e-858d-d0d0ddcd3e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for images 20000:21000 saved to ./20000_to_21000.csv\n",
      "Results for images 21000:22000 saved to ./21000_to_22000.csv\n",
      "Results for images 22000:23000 saved to ./22000_to_23000.csv\n",
      "Results for images 23000:24000 saved to ./23000_to_24000.csv\n",
      "Results for images 24000:25000 saved to ./24000_to_25000.csv\n",
      "Results for images 25000:26000 saved to ./25000_to_26000.csv\n",
      "Results for images 26000:27000 saved to ./26000_to_27000.csv\n",
      "Results for images 27000:28000 saved to ./27000_to_28000.csv\n",
      "Results for images 28000:29000 saved to ./28000_to_29000.csv\n",
      "Results for images 29000:30000 saved to ./29000_to_30000.csv\n",
      "Results for images 30000:31000 saved to ./30000_to_31000.csv\n",
      "Results for images 31000:32000 saved to ./31000_to_32000.csv\n",
      "Results for images 32000:33000 saved to ./32000_to_33000.csv\n",
      "Results for images 33000:34000 saved to ./33000_to_34000.csv\n",
      "Results for images 34000:35000 saved to ./34000_to_35000.csv\n",
      "Results for images 35000:36000 saved to ./35000_to_36000.csv\n",
      "Results for images 36000:37000 saved to ./36000_to_37000.csv\n",
      "Results for images 37000:38000 saved to ./37000_to_38000.csv\n",
      "Results for images 38000:39000 saved to ./38000_to_39000.csv\n",
      "Results for images 39000:40000 saved to ./39000_to_40000.csv\n",
      "Results for images 40000:41000 saved to ./40000_to_41000.csv\n",
      "All batches have been processed.\n"
     ]
    }
   ],
   "source": [
    "# process results for each finished job\n",
    "# for each job........\n",
    "for job_id, job in completed_jobs.items():\n",
    "    meta = jobs[job_id]\n",
    "    starter_val = meta[\"starter_val\"]\n",
    "    step = meta[\"step\"]\n",
    "    \n",
    "    # get the output file id and contents\n",
    "    result_file_id = job.output_file_id\n",
    "    result_content = client.files.content(result_file_id).content\n",
    "\n",
    "    # write raw results to a jsonl file\n",
    "    result_file_name = f\"./{starter_val}_to_{starter_val+step}_batch.jsonl\"\n",
    "    with open(result_file_name, 'wb') as file:\n",
    "        file.write(result_content)\n",
    "    \n",
    "    # parse the jsonl file into results\n",
    "    results = []\n",
    "    with open(result_file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            json_object = json.loads(line.strip())\n",
    "            results.append(json_object)\n",
    "    \n",
    "    # extract indices corresponding answers from the results\n",
    "    idxs = [int(item['custom_id'].split('-')[1]) for item in results]\n",
    "    answers = [item['response']['body']['choices'][0]['message']['content'] for item in results]\n",
    "    \n",
    "    # sort em\n",
    "    sorted_idx_answers = sorted(zip(idxs, answers))\n",
    "    if sorted_idx_answers:\n",
    "        sorted_idxs, sorted_answers = zip(*sorted_idx_answers)\n",
    "    else:\n",
    "        sorted_idxs, sorted_answers = ([], [])\n",
    "    \n",
    "    # get a a full list of answers for this batch (mark missing idxs \"FAILED\")\n",
    "    complete_answers = []\n",
    "    for i in range(step):\n",
    "        if i in sorted_idxs:\n",
    "            answer = sorted_answers[sorted_idxs.index(i)]\n",
    "            complete_answers.append(answer)\n",
    "        else:\n",
    "            complete_answers.append(\"FAILED\")\n",
    "    \n",
    "    # write results to a csv file\n",
    "    output_csv = f\"./{starter_val}_to_{starter_val+step}.csv\"\n",
    "    with open(output_csv, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"flower_present\"])  # Optional header row\n",
    "        for ans in complete_answers:\n",
    "            writer.writerow([ans])\n",
    "    \n",
    "    print(f\"Results for images {starter_val}:{starter_val+step} saved to {output_csv}\")\n",
    "\n",
    "print(\"All batches have been processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf95c6-19a3-4115-a3d7-74acbb4d0d98",
   "metadata": {},
   "source": [
    "# Finish up the last few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbee6b11-c980-4955-98b1-6563d009ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_overall = 41000\n",
    "stop_overall = 41069\n",
    "# make a list of file paths to images\n",
    "file_names = [str(i)+'.jpg' for i in range(start_overall,stop_overall)]\n",
    "file_paths = [os.path.join('/Volumes/My Passport/monarda_fistulosa_segmentation/image_dataset/images/',i) for i in file_names]\n",
    "\n",
    "# write out local batch submission file\n",
    "start = 0\n",
    "stop = len(file_paths)  # ensure we don't exceed the number of images\n",
    "file_name = f\"batch_tasks_loop.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for idx in range(start, stop):\n",
    "        task = process_image(idx, file_paths[idx])\n",
    "        if task:\n",
    "            file.write(json.dumps(task) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ce52338-66be-46a0-8efb-1d7e6542e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the batch file to api\n",
    "batch_file = client.files.create(\n",
    "    file=open(file_name, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_job = client.batches.create(\n",
    "    input_file_id=batch_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60d4a7e0-0b7f-48c3-b30d-4524e608400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for results\n",
    "batch_job = client.batches.retrieve(batch_job.id)\n",
    "\n",
    "while not client.batches.retrieve(batch_job.id).completed_at:\n",
    "    time.sleep(60)\n",
    "    if client.batches.retrieve(batch_job.id).failed_at:\n",
    "        print('job failed!')\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "batch_job = client.batches.retrieve(batch_job.id)\n",
    "\n",
    "# get results\n",
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content\n",
    "\n",
    "# write results to file\n",
    "result_file_name = f\"./{start_overall}_to_{stop_overall}_batch.jsonl\"\n",
    "\n",
    "with open(result_file_name, 'wb') as file:\n",
    "    file.write(result)\n",
    "\n",
    "#Â load data from file\n",
    "results = []\n",
    "with open(result_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        # parse the json to a dict and append to results list\n",
    "        json_object = json.loads(line.strip())\n",
    "        results.append(json_object)\n",
    "idxs = [int(i['custom_id'].split('-')[1]) for i in results]\n",
    "answers = [i['response']['body']['choices'][0]['message']['content'] for i in results]\n",
    "\n",
    "#handle failed queries and sort\n",
    "# first zip and sort\n",
    "sorted_idx_answers = sorted(zip(idxs, answers))\n",
    "\n",
    "# separate sorted pairs\n",
    "sorted_idxs, sorted_answers = zip(*sorted_idx_answers)\n",
    "\n",
    "# init the full list of answers\n",
    "complete_answers = []\n",
    "\n",
    "# iter through the expected range of idxs\n",
    "for i in range(start,stop):\n",
    "    if i in sorted_idxs:\n",
    "        # get corresponding answer\n",
    "        answer = sorted_answers[sorted_idxs.index(i)]\n",
    "        complete_answers.append(answer)\n",
    "    else:\n",
    "        # fill in missing idxs = \"FAILED\"\n",
    "        complete_answers.append(\"FAILED\")\n",
    "\n",
    "# write to csv\n",
    "# define output csv name\n",
    "output_file = f\"./{start_overall}_to_{stop_overall}.csv\"\n",
    "\n",
    "# write list to single column csv file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"flower_present\"])\n",
    "    for item in complete_answers:\n",
    "        writer.writerow([item])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
